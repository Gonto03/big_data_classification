{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work by: GonÃ§alo Dias and Vicente Bandeira"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as both an implementation and a report for the work proposed to us in the CDLE cadeira in IACD. In this report, we present the findings of our comprehensive analysis of machine learning performance using various Python libraries for big data processing. As the scale and complexity of data continue to grow, the choice of tools and libraries becomes critical in ensuring efficient and effective machine learning workflows. To address this, we executed a full Machine Learning Pipeline using several prominent big data libraries: PySpark, Dask, Modin, JobLib, Rapids and Koalas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 1: Repeating the NYC taxi driver dataset study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.databricks.com/blog/2021/04/07/benchmark-koalas-pyspark-and-dask.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:17.981408Z",
     "start_time": "2024-06-03T09:52:17.975900Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:18.463310Z",
     "start_time": "2024-06-03T09:52:18.123271Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Iterable' from 'collections' (C:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\collections\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatabricks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkoalas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mks\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdd\u001b[39;00m\n",
      "File \u001b[1;32md:\\uni\\big_data_classification\\venv\\Lib\\site-packages\\databricks\\koalas\\__init__.py:74\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease explicitly unset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mARROW_PRE_0_15_IPC_FORMAT\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m environment variable in both \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver and executor sides. It is required to set this environment variable only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhen you use pyarrow>=0.15 and pyspark<3.0.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     70\u001b[0m     )\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatabricks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkoalas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatabricks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkoalas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Index, MultiIndex\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatabricks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkoalas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatabricks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkoalas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypedef\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pandas_wraps\n",
      "File \u001b[1;32md:\\uni\\big_data_classification\\venv\\Lib\\site-packages\\databricks\\koalas\\indexes.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatabricks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkoalas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatabricks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkoalas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mindexes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MissingPandasLikeIndex, _MissingPandasLikeMultiIndex\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatabricks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkoalas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseries\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series, _col\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatabricks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkoalas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m     compare_allow_null,\n\u001b[0;32m     54\u001b[0m     compare_disallow_null,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     validate_bool_kwarg,\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatabricks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkoalas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _InternalFrame, NATURAL_ORDER_COLUMN_NAME\n",
      "File \u001b[1;32md:\\uni\\big_data_classification\\venv\\Lib\\site-packages\\databricks\\koalas\\series.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable, OrderedDict\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial, wraps, reduce\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Generic, List, Optional, Tuple, TypeVar, Union\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Iterable' from 'collections' (C:\\Users\\vicen\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\collections\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import databricks.koalas as ks\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client, LocalCluster\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print('pandas version: %s' % pd.__version__)\n",
    "print('numpy version: %s' % np.__version__)\n",
    "print('koalas version: %s' % ks.__version__)\n",
    "print('dask version: %s' % dask.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"../yellow_tripdata_2011-01.parquet\"\n",
    "koalas_data = ks.read_parquet(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:18.513197Z",
     "start_time": "2024-06-03T09:52:18.477271Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'koalas_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of rows:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mkoalas_data\u001b[49m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(koalas_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m20\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'koalas_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows:\", len(koalas_data))\n",
    "print()\n",
    "print(koalas_data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "koalas_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:18.597963Z",
     "start_time": "2024-06-03T09:52:18.564058Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'koalas_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m expr_filter \u001b[38;5;241m=\u001b[39m (\u001b[43mkoalas_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtip_amount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m (koalas_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtip_amount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFiltered data is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(koalas_data[expr_filter])\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(koalas_data)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% of total data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'koalas_data' is not defined"
     ]
    }
   ],
   "source": [
    "expr_filter = (koalas_data['tip_amount'] >= 1) & (koalas_data['tip_amount'] <= 5)\n",
    " \n",
    "print(f'Filtered data is {len(koalas_data[expr_filter]) / len(koalas_data) * 100}% of total data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:18.709956Z",
     "start_time": "2024-06-03T09:52:18.691710Z"
    }
   },
   "outputs": [],
   "source": [
    "def benchmark(f, df, benchmarks, name, **kwargs):\n",
    "    \"\"\"Benchmark the given function against the given DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f: function to benchmark\n",
    "    df: data frame\n",
    "    benchmarks: container for benchmark results\n",
    "    name: task name\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Duration (in seconds) of the given operation\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    ret = f(df, **kwargs)\n",
    "    benchmarks['duration'].append(time.time() - start_time)\n",
    "    benchmarks['task'].append(name)\n",
    "    print(f\"{name} took: {benchmarks['duration'][-1]} seconds\")\n",
    "\n",
    "def get_results(benchmarks):\n",
    "    \"\"\"Return a pandas DataFrame containing benchmark results.\"\"\"\n",
    "    return pd.DataFrame.from_dict(benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:18.760344Z",
     "start_time": "2024-06-03T09:52:18.743864Z"
    }
   },
   "outputs": [],
   "source": [
    "paths = [\"../yellow_tripdata_201\"+str(i)+\"-01.parquet\" for i in range(1,4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koalas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we utilized the Koalas library for our experiments, trying it on Standard operations, operations with filtering and operations with filtering and caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:18.867069Z",
     "start_time": "2024-06-03T09:52:18.794252Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m koalas_data \u001b[38;5;241m=\u001b[39m \u001b[43mks\u001b[49m\u001b[38;5;241m.\u001b[39mread_parquet(paths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ks' is not defined"
     ]
    }
   ],
   "source": [
    "koalas_data = ks.read_parquet(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:18.905206Z",
     "start_time": "2024-06-03T09:52:18.900976Z"
    }
   },
   "outputs": [],
   "source": [
    "koalas_benchmarks = {\n",
    "    'duration': [],     # in seconds\n",
    "    'task': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.008954Z",
     "start_time": "2024-06-03T09:52:18.925126Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 74\u001b[0m\n\u001b[0;32m     66\u001b[0m     gb \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassenger_count\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg(\n\u001b[0;32m     67\u001b[0m       {\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtip_amount\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     70\u001b[0m       }\n\u001b[0;32m     71\u001b[0m     )\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gb\n\u001b[1;32m---> 74\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[43mks\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(groupby_statistics(koalas_data)\u001b[38;5;241m.\u001b[39mto_pandas())\n\u001b[0;32m     75\u001b[0m other\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mIndex([e[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m e[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m other\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()])\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin_count\u001b[39m(df, other):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ks' is not defined"
     ]
    }
   ],
   "source": [
    "def read_file_parquet(df=None):\n",
    "    return ks.read_parquet(\"../yellow_tripdata_2011-01.parquet\")\n",
    "\n",
    "def count(df=None):\n",
    "    return len(df)\n",
    "\n",
    "def count_index_length(df=None):\n",
    "    return len(df.index)\n",
    "\n",
    "def mean(df):\n",
    "    return df.fare_amount.mean()\n",
    "\n",
    "def standard_deviation(df):\n",
    "    return df.fare_amount.std()\n",
    "\n",
    "def mean_of_sum(df):\n",
    "    return (df.fare_amount + df.tip_amount).mean()\n",
    "\n",
    "def sum_columns(df):\n",
    "    x = df.fare_amount + df.tip_amount\n",
    "    return x\n",
    "\n",
    "def mean_of_product(df):\n",
    "    return (df.fare_amount * df.tip_amount).mean()\n",
    "\n",
    "def product_columns(df):\n",
    "    x = df.fare_amount * df.tip_amount\n",
    "    return x\n",
    "\n",
    "def value_counts(df):\n",
    "    val_counts = df.fare_amount.value_counts()\n",
    "    return val_counts\n",
    "\n",
    "\n",
    "#   In the original experiment, the following two functions used the longitude and latitude values of the pickup and the dropout places.\n",
    "#   Since the datasets provided by NYC TLC Trip Record Data no longer have longitude and latitude values (only the pickup and dropout places IDs),\n",
    "# we used arbitrary longitude and latitude values. The goal of this experiment is to compare the computational cost of the calculations, hence\n",
    "# the values are not relevant.\n",
    "def complicated_arithmetic_operation(df):\n",
    "    start_lon,end_lon = np.random.randint(-180,180),np.random.randint(-180,180)\n",
    "    start_lat,end_lat = np.random.randint(-90,90),np.random.randint(-90,90)\n",
    "    \n",
    "    theta_1 = start_lon\n",
    "    phi_1 = start_lat\n",
    "    theta_2 = end_lon\n",
    "    phi_2 = end_lat\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "           + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "    ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(1-temp)),2)\n",
    "    return ret\n",
    "\n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    start_lon,end_lon = np.random.randint(-180,180),np.random.randint(-180,180)\n",
    "    start_lat,end_lat = np.random.randint(-90,90),np.random.randint(-90,90)\n",
    "    \n",
    "    theta_1 = start_lon\n",
    "    phi_1 = start_lat\n",
    "    theta_2 = end_lon\n",
    "    phi_2 = end_lat\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "           + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "    ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(1-temp)),2) \n",
    "    return ret.mean()\n",
    "\n",
    "def groupby_statistics(df):\n",
    "    gb = df.groupby(by='passenger_count').agg(\n",
    "      {\n",
    "        'fare_amount': ['mean', 'std'], \n",
    "        'tip_amount': ['mean', 'std']\n",
    "      }\n",
    "    )\n",
    "    return gb\n",
    "\n",
    "other = ks.DataFrame(groupby_statistics(koalas_data).to_pandas())\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "def join_count(df, other):\n",
    "    return len(df.merge(other.spark.hint(\"broadcast\"), left_index=True, right_index=True))\n",
    "\n",
    "def join_data(df, other):\n",
    "    ret = df.merge(other.spark.hint(\"broadcast\"), left_index=True, right_index=True)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.012936Z",
     "start_time": "2024-06-03T09:52:19.011938Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark(read_file_parquet, df=None, benchmarks=koalas_benchmarks, name='read file')\n",
    "benchmark(count, df=koalas_data, benchmarks=koalas_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=koalas_data, benchmarks=koalas_benchmarks, name='count index length')\n",
    "benchmark(mean, df=koalas_data, benchmarks=koalas_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=koalas_data, benchmarks=koalas_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of columns addition')\n",
    "benchmark(sum_columns, df=koalas_data, benchmarks=koalas_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of columns multiplication')\n",
    "benchmark(product_columns, df=koalas_data, benchmarks=koalas_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=koalas_data, benchmarks=koalas_benchmarks, name='value counts')\n",
    "benchmark(complicated_arithmetic_operation, df=koalas_data, benchmarks=koalas_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=koalas_data, benchmarks=koalas_benchmarks, name='mean of complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=koalas_data, benchmarks=koalas_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, koalas_data, benchmarks=koalas_benchmarks, name='join count', other=other)\n",
    "benchmark(join_data, koalas_data, benchmarks=koalas_benchmarks, name='join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_filter = (koalas_data.tip_amount >= 1) & (koalas_data.tip_amount <= 5)\n",
    "\n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    "\n",
    "koalas_filtered = filter_data(koalas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.055387Z",
     "start_time": "2024-06-03T09:52:19.023908Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'koalas_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m benchmark(count, \u001b[43mkoalas_filtered\u001b[49m, benchmarks\u001b[38;5;241m=\u001b[39mkoalas_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m benchmark(count_index_length, koalas_filtered, benchmarks\u001b[38;5;241m=\u001b[39mkoalas_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count index length\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m benchmark(mean, koalas_filtered, benchmarks\u001b[38;5;241m=\u001b[39mkoalas_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered mean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'koalas_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "benchmark(count, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered mean of columns addition')\n",
    "benchmark(sum_columns, df=koalas_filtered, benchmarks=koalas_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered mean of columns multiplication')\n",
    "benchmark(product_columns, df=koalas_filtered, benchmarks=koalas_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "benchmark(complicated_arithmetic_operation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered groupby statistics')\n",
    "\n",
    "other = ks.DataFrame(groupby_statistics(koalas_filtered).to_pandas())\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "benchmark(join_data, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered join', other=other)\n",
    "benchmark(join_count, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered join count', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations with filtering and caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.058377Z",
     "start_time": "2024-06-03T09:52:19.057380Z"
    }
   },
   "outputs": [],
   "source": [
    "koalas_filtered_cached = koalas_filtered.spark.cache()\n",
    "print(f'Enforce caching: {len(koalas_filtered_cached)} rows of filtered data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.102249Z",
     "start_time": "2024-06-03T09:52:19.065359Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'koalas_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m benchmark(count, \u001b[43mkoalas_filtered\u001b[49m, benchmarks\u001b[38;5;241m=\u001b[39mkoalas_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m benchmark(count_index_length, koalas_filtered, benchmarks\u001b[38;5;241m=\u001b[39mkoalas_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count index length\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m benchmark(mean, koalas_filtered, benchmarks\u001b[38;5;241m=\u001b[39mkoalas_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered mean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'koalas_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "benchmark(count, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered mean of columns addition')\n",
    "benchmark(sum_columns, df=koalas_filtered, benchmarks=koalas_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered mean of columns multiplication')\n",
    "benchmark(product_columns, df=koalas_filtered, benchmarks=koalas_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "benchmark(complicated_arithmetic_operation, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, koalas_filtered, benchmarks=koalas_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered groupby statistics')\n",
    "\n",
    "other = ks.DataFrame(groupby_statistics(koalas_filtered).to_pandas())\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "benchmark(join_data, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered join', other=other)\n",
    "benchmark(join_count, koalas_filtered, benchmarks=koalas_benchmarks, name='filtered join count', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeated this experiment with Dask, on the same 3 sets of operations: standard, with filtering and with filtering and caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.198058Z",
     "start_time": "2024-06-03T09:52:19.178437Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LocalCluster' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cluster \u001b[38;5;241m=\u001b[39m \u001b[43mLocalCluster\u001b[49m(memory_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8GB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m Client(cluster)\n\u001b[0;32m      4\u001b[0m dask_data \u001b[38;5;241m=\u001b[39m dd\u001b[38;5;241m.\u001b[39mread_parquet(paths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LocalCluster' is not defined"
     ]
    }
   ],
   "source": [
    "cluster = LocalCluster(memory_limit='8GB')\n",
    "client = Client(cluster)\n",
    "\n",
    "dask_data = dd.read_parquet(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.235960Z",
     "start_time": "2024-06-03T09:52:19.231966Z"
    }
   },
   "outputs": [],
   "source": [
    "dask_benchmarks = {\n",
    "    'duration': [],  # in seconds\n",
    "    'task': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.314412Z",
     "start_time": "2024-06-03T09:52:19.261871Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dask_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 65\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgroupby_statistics\u001b[39m(df):\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mgroupby(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassenger_count\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfare_amount\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtip_amount\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m] \n\u001b[0;32m     63\u001b[0m     })\n\u001b[1;32m---> 65\u001b[0m other \u001b[38;5;241m=\u001b[39m groupby_statistics(\u001b[43mdask_data\u001b[49m)\n\u001b[0;32m     66\u001b[0m other\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mIndex([e[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m e[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m other\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()])\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjoin_count\u001b[39m(df, other):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dask_data' is not defined"
     ]
    }
   ],
   "source": [
    "def read_file_parquet(df=None):\n",
    "    return dd.read_parquet(\"../yellow_tripdata_2011-01.parquet\")\n",
    "\n",
    "def count(df=None):\n",
    "    return len(df)\n",
    "\n",
    "def count_index_length(df=None):\n",
    "    return len(df.index)\n",
    "\n",
    "def mean(df):\n",
    "    return df.fare_amount.mean().compute()\n",
    "\n",
    "def standard_deviation(df):\n",
    "    return df.fare_amount.std().compute()\n",
    "\n",
    "def mean_of_sum(df):\n",
    "    return (df.fare_amount + df.tip_amount).mean().compute()\n",
    "\n",
    "def sum_columns(df):\n",
    "    return (df.fare_amount + df.tip_amount).compute()\n",
    "\n",
    "def mean_of_product(df):\n",
    "    return (df.fare_amount * df.tip_amount).mean().compute()\n",
    "\n",
    "def product_columns(df):\n",
    "    return (df.fare_amount * df.tip_amount).compute()\n",
    "\n",
    "def value_counts(df):\n",
    "    return df.fare_amount.value_counts().compute()\n",
    "\n",
    "#   In the original experiment, the following two functions used the longitude and latitude values of the pickup and the dropout places.\n",
    "#   Since the datasets provided by NYC TLC Trip Record Data no longer have longitude and latitude values (only the pickup and dropout places IDs),\n",
    "# we used arbitrary longitude and latitude values. The goal of this experiment is to compare the computational cost of the calculations, hence\n",
    "# the values are not relevant.\n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    start_lon,end_lon = np.random.randint(-180,180),np.random.randint(-180,180)\n",
    "    start_lat,end_lat = np.random.randint(-90,90),np.random.randint(-90,90)\n",
    "    theta_1 = start_lon\n",
    "    phi_1 = start_lat\n",
    "    theta_2 = end_lon\n",
    "    phi_2 = end_lat\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "    return ret.mean()\n",
    "\n",
    "def complicated_arithmetic_operation(df):\n",
    "    start_lon,end_lon = np.random.randint(-180,180),np.random.randint(-180,180)\n",
    "    start_lat,end_lat = np.random.randint(-90,90),np.random.randint(-90,90)\n",
    "    theta_1 = start_lon\n",
    "    phi_1 = start_lat\n",
    "    theta_2 = end_lon\n",
    "    phi_2 = end_lat\n",
    "    temp = (np.sin((theta_2-theta_1)/2*np.pi/180)**2\n",
    "           + np.cos(theta_1*np.pi/180)*np.cos(theta_2*np.pi/180) * np.sin((phi_2-phi_1)/2*np.pi/180)**2)\n",
    "    ret = 2 * np.arctan2(np.sqrt(temp), np.sqrt(1-temp))\n",
    "    return ret\n",
    "\n",
    "def groupby_statistics(df):\n",
    "    return df.groupby(by='passenger_count').agg({\n",
    "        'fare_amount': ['mean', 'std'],\n",
    "        'tip_amount': ['mean', 'std'] \n",
    "    })\n",
    "\n",
    "other = groupby_statistics(dask_data)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "def join_count(df, other):\n",
    "    return len(dd.merge(df, other, left_index=True, right_index=True))\n",
    "\n",
    "def join_data(df, other):\n",
    "    return dd.merge(df, other, left_index=True, right_index=True).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.366222Z",
     "start_time": "2024-06-03T09:52:19.327370Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbenchmark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mread_file_parquet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbenchmarks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdask_benchmarks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mread file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m benchmark(count, df\u001b[38;5;241m=\u001b[39mdask_data, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m benchmark(count_index_length, df\u001b[38;5;241m=\u001b[39mdask_data, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount index length\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m, in \u001b[0;36mbenchmark\u001b[1;34m(f, df, benchmarks, name, **kwargs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbenchmark\u001b[39m(f, df, benchmarks, name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Benchmark the given function against the given DataFrame.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    Duration (in seconds) of the given operation\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     18\u001b[0m     ret \u001b[38;5;241m=\u001b[39m f(df, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     19\u001b[0m     benchmarks[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "benchmark(read_file_parquet, df=None, benchmarks=dask_benchmarks, name='read file')\n",
    "benchmark(count, df=dask_data, benchmarks=dask_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=dask_data, benchmarks=dask_benchmarks, name='count index length')\n",
    "benchmark(mean, df=dask_data, benchmarks=dask_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=dask_data, benchmarks=dask_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=dask_data, benchmarks=dask_benchmarks, name='mean of columns addition')\n",
    "benchmark(sum_columns, df=dask_data, benchmarks=dask_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=dask_data, benchmarks=dask_benchmarks, name='mean of columns multiplication')\n",
    "benchmark(product_columns, df=dask_data, benchmarks=dask_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=dask_data, benchmarks=dask_benchmarks, name='value counts')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='mean of complex arithmetic ops')\n",
    "benchmark(complicated_arithmetic_operation, df=dask_data, benchmarks=dask_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=dask_data, benchmarks=dask_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, dask_data, benchmarks=dask_benchmarks, name='join count', other=other)\n",
    "benchmark(join_data, dask_data, benchmarks=dask_benchmarks, name='join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_filter = (dask_data.tip_amount >= 1) & (dask_data.tip_amount <= 5)\n",
    "\n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    "\n",
    "dask_filtered = filter_data(dask_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.416600Z",
     "start_time": "2024-06-03T09:52:19.385172Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dask_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m benchmark(count, \u001b[43mdask_filtered\u001b[49m, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m benchmark(count_index_length, dask_filtered, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count index length\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m benchmark(mean, dask_filtered, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered mean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dask_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "benchmark(count, dask_filtered, benchmarks=dask_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, dask_filtered, benchmarks=dask_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, dask_filtered, benchmarks=dask_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, dask_filtered, benchmarks=dask_benchmarks, name ='filtered mean of columns addition')\n",
    "benchmark(sum_columns, df=dask_filtered, benchmarks=dask_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, dask_filtered, benchmarks=dask_benchmarks, name ='filtered mean of columns multiplication')\n",
    "benchmark(product_columns, df=dask_filtered, benchmarks=dask_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "benchmark(complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, dask_filtered, benchmarks=dask_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, dask_filtered, benchmarks=dask_benchmarks, name='filtered groupby statistics')\n",
    "\n",
    "other = groupby_statistics(dask_filtered)\n",
    "other.columns = pd.Index([e[0] +'_'+ e[1] for e in other.columns.tolist()])\n",
    "\n",
    "benchmark(join_count, dask_filtered, benchmarks=dask_benchmarks, name='filtered join count', other=other)\n",
    "benchmark(join_data, dask_filtered, benchmarks=dask_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations with filtering and caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.418593Z",
     "start_time": "2024-06-03T09:52:19.418593Z"
    }
   },
   "outputs": [],
   "source": [
    "dask_filtered = client.persist(dask_filtered)\n",
    "\n",
    "from distributed import wait\n",
    "print('Waiting until all futures are finished')\n",
    "wait(dask_filtered)\n",
    "print('All futures are finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.452516Z",
     "start_time": "2024-06-03T09:52:19.424577Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dask_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m benchmark(count, \u001b[43mdask_filtered\u001b[49m, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m benchmark(count_index_length, dask_filtered, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count index length\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m benchmark(mean, dask_filtered, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered mean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dask_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "benchmark(count, dask_filtered, benchmarks=dask_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, dask_filtered, benchmarks=dask_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, dask_filtered, benchmarks=dask_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, dask_filtered, benchmarks=dask_benchmarks, name ='filtered mean of columns addition')\n",
    "benchmark(sum_columns, df=dask_filtered, benchmarks=dask_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, dask_filtered, benchmarks=dask_benchmarks, name ='filtered mean of columns multiplication')\n",
    "benchmark(product_columns, df=dask_filtered, benchmarks=dask_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "benchmark(complicated_arithmetic_operation, dask_filtered, benchmarks=dask_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, dask_filtered, benchmarks=dask_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, dask_filtered, benchmarks=dask_benchmarks, name='filtered groupby statistics')\n",
    "\n",
    "other = groupby_statistics(dask_filtered)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "benchmark(join_count, dask_filtered, benchmarks=dask_benchmarks, name='filtered join count', other=other)\n",
    "benchmark(join_data, dask_filtered, benchmarks=dask_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.495850Z",
     "start_time": "2024-06-03T09:52:19.475450Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mrestart()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.504209Z",
     "start_time": "2024-06-03T09:52:19.498836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'duration': [], 'task': []}\n",
      "{'duration': [], 'task': []}\n"
     ]
    }
   ],
   "source": [
    "print(koalas_benchmarks)\n",
    "print(dask_benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T09:52:19.873807Z",
     "start_time": "2024-06-03T09:52:19.867667Z"
    }
   },
   "outputs": [],
   "source": [
    "dask_koalas_duration_ratio = []\n",
    "i=0\n",
    "for task in dask_benchmarks['task']:\n",
    "    ratio = dask_benchmarks['duration'][i]/koalas_benchmarks['duration'][i]\n",
    "    dask_koalas_duration_ratio.append(ratio)\n",
    "    if ratio >= 1:\n",
    "        print(f\"Task {task}: Koalas performs {ratio}x better than Dask\")\n",
    "    else:\n",
    "        print(f\"Task {task}: Dask performs {1/ratio}x better than Koalas\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT 2: Running datasets with different combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dask + Modin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as mpd\n",
    "from modin.config import Engine\n",
    "\n",
    "print('modin version: %s' % mpd.__version__)\n",
    "\n",
    "Engine.put(\"dask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_modin_data = mpd.read_parquet(paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_modin_benchmarks = {\n",
    "    'duration': [],     # in seconds\n",
    "    'task': []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_parquet(df=None):\n",
    "    return mpd.read_parquet(\"../yellow_tripdata_2011-01.parquet\")\n",
    "\n",
    "def count(df=None):\n",
    "    return len(df)\n",
    "\n",
    "def count_index_length(df=None):\n",
    "    return len(df.index)\n",
    "\n",
    "def mean(df):\n",
    "    return df.fare_amount.mean()\n",
    "\n",
    "def standard_deviation(df):\n",
    "    return df.fare_amount.std()\n",
    "\n",
    "def mean_of_sum(df):\n",
    "    return (df.fare_amount + df.tip_amount).mean()\n",
    "\n",
    "def sum_columns(df):\n",
    "    x = df.fare_amount + df.tip_amount\n",
    "    return x\n",
    "\n",
    "def mean_of_product(df):\n",
    "    return (df.fare_amount * df.tip_amount).mean()\n",
    "\n",
    "def product_columns(df):\n",
    "    x = df.fare_amount * df.tip_amount\n",
    "    return x\n",
    "\n",
    "def value_counts(df):\n",
    "    val_counts = df.fare_amount.value_counts()\n",
    "    return val_counts\n",
    "\n",
    "\n",
    "#   In the original experiment, the following two functions used the longitude and latitude values of the pickup and the dropout places.\n",
    "#   Since the datasets provided by NYC TLC Trip Record Data no longer have longitude and latitude values (only the pickup and dropout places IDs),\n",
    "# we used arbitrary longitude and latitude values. The goal of this experiment is to compare the computational cost of the calculations, hence\n",
    "# the values are not relevant.\n",
    "def complicated_arithmetic_operation(df):\n",
    "    start_lon,end_lon = np.random.randint(-180,180),np.random.randint(-180,180)\n",
    "    start_lat,end_lat = np.random.randint(-90,90),np.random.randint(-90,90)\n",
    "    \n",
    "    theta_1 = start_lon\n",
    "    phi_1 = start_lat\n",
    "    theta_2 = end_lon\n",
    "    phi_2 = end_lat\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "           + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "    ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(1-temp)),2)\n",
    "    return ret\n",
    "\n",
    "def mean_of_complicated_arithmetic_operation(df):\n",
    "    start_lon,end_lon = np.random.randint(-180,180),np.random.randint(-180,180)\n",
    "    start_lat,end_lat = np.random.randint(-90,90),np.random.randint(-90,90)\n",
    "    \n",
    "    theta_1 = start_lon\n",
    "    phi_1 = start_lat\n",
    "    theta_2 = end_lon\n",
    "    phi_2 = end_lat\n",
    "    temp = (np.sin((theta_2 - theta_1) / 2 * np.pi / 180) ** 2\n",
    "           + np.cos(theta_1 * np.pi / 180) * np.cos(theta_2 * np.pi / 180) * np.sin((phi_2 - phi_1) / 2 * np.pi / 180) ** 2)\n",
    "    ret = np.multiply(np.arctan2(np.sqrt(temp), np.sqrt(1-temp)),2) \n",
    "    return ret.mean()\n",
    "\n",
    "def groupby_statistics(df):\n",
    "    gb = df.groupby(by='passenger_count').agg(\n",
    "      {\n",
    "        'fare_amount': ['mean', 'std'], \n",
    "        'tip_amount': ['mean', 'std']\n",
    "      }\n",
    "    )\n",
    "    return gb\n",
    "\n",
    "other = groupby_statistics(dask_modin_data)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "def join_count(df, other):\n",
    "    return len(mpd.merge(df, other, left_index=True, right_index=True))\n",
    "\n",
    "def join_data(df, other):\n",
    "    return mpd.merge(df, other, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark(read_file_parquet, df=None, benchmarks=dask_modin_benchmarks, name='read file')\n",
    "benchmark(count, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='count')\n",
    "benchmark(count_index_length, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='count index length')\n",
    "benchmark(mean, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='mean')\n",
    "benchmark(standard_deviation, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='standard deviation')\n",
    "benchmark(mean_of_sum, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='mean of columns addition')\n",
    "benchmark(sum_columns, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='addition of columns')\n",
    "benchmark(mean_of_product, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='mean of columns multiplication')\n",
    "benchmark(product_columns, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='multiplication of columns')\n",
    "benchmark(value_counts, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='value counts')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='mean of complex arithmetic ops')\n",
    "benchmark(complicated_arithmetic_operation, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='complex arithmetic ops')\n",
    "benchmark(groupby_statistics, df=dask_modin_data, benchmarks=dask_modin_benchmarks, name='groupby statistics')\n",
    "benchmark(join_count, dask_modin_data, benchmarks=dask_modin_benchmarks, name='join count', other=other)\n",
    "benchmark(join_data, dask_modin_data, benchmarks=dask_modin_benchmarks, name='join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations with filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_filter = (dask_modin_data.tip_amount >= 1) & (dask_modin_data.tip_amount <= 5)\n",
    "\n",
    "def filter_data(df):\n",
    "    return df[expr_filter]\n",
    "\n",
    "dask_modin_filtered = filter_data(dask_modin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dask_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m benchmark(count, \u001b[43mdask_filtered\u001b[49m, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m      2\u001b[0m benchmark(count_index_length, dask_filtered, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count index length\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m      3\u001b[0m benchmark(mean, dask_filtered, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered mean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dask_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "benchmark(count, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name ='filtered mean of columns addition')\n",
    "benchmark(sum_columns, df=dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name ='filtered mean of columns multiplication')\n",
    "benchmark(product_columns, df=dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "benchmark(complicated_arithmetic_operation, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered groupby statistics')\n",
    "\n",
    "other = groupby_statistics(dask_modin_filtered)\n",
    "other.columns = pd.Index([e[0] +'_'+ e[1] for e in other.columns.tolist()])\n",
    "\n",
    "benchmark(join_count, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered join count', other=other)\n",
    "benchmark(join_data, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations with filtering and caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask_modin_filtered = client.persist(dask_modin_filtered)\n",
    "\n",
    "from distributed import wait\n",
    "print('Waiting until all futures are finished')\n",
    "wait(dask_modin_filtered)\n",
    "print('All futures are finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dask_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m benchmark(count, \u001b[43mdask_filtered\u001b[49m, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m      2\u001b[0m benchmark(count_index_length, dask_filtered, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered count index length\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;32m      3\u001b[0m benchmark(mean, dask_filtered, benchmarks\u001b[38;5;241m=\u001b[39mdask_benchmarks, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered mean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dask_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "benchmark(count, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered count')\n",
    "benchmark(count_index_length, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered count index length')\n",
    "benchmark(mean, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered mean')\n",
    "benchmark(standard_deviation, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered standard deviation')\n",
    "benchmark(mean_of_sum, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name ='filtered mean of columns addition')\n",
    "benchmark(sum_columns, df=dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered addition of columns')\n",
    "benchmark(mean_of_product, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name ='filtered mean of columns multiplication')\n",
    "benchmark(product_columns, df=dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered multiplication of columns')\n",
    "benchmark(mean_of_complicated_arithmetic_operation, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered mean of complex arithmetic ops')\n",
    "benchmark(complicated_arithmetic_operation, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered complex arithmetic ops')\n",
    "benchmark(value_counts, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name ='filtered value counts')\n",
    "benchmark(groupby_statistics, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered groupby statistics')\n",
    "\n",
    "other = groupby_statistics(dask_modin_filtered)\n",
    "other.columns = pd.Index([e[0]+'_' + e[1] for e in other.columns.tolist()])\n",
    "\n",
    "benchmark(join_count, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered join count', other=other)\n",
    "benchmark(join_data, dask_modin_filtered, benchmarks=dask_modin_benchmarks, name='filtered join', other=other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mrestart()\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
